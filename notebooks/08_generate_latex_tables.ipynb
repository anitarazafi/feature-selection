{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7df11c-4c04-43bf-b4d7-c52032109141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LATEX TABLE GENERATOR FOR THESIS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"LaTeX Table Generator\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9f27d-96be-4e6e-ae13-58234a3f9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. LOAD COMBINED RESULTS\n",
    "# ============================================================\n",
    "\n",
    "all_results = pd.read_csv(\"results/comparisons/tables/all_methods_combined.csv\")\n",
    "baseline = all_results[all_results['method'] == 'baseline']\n",
    "\n",
    "print(f\"âœ“ Loaded {len(all_results)} experiments\")\n",
    "print(f\"âœ“ Methods: {all_results['method'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4de37-3658-44dd-9cf6-7a06c1c5bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. TABLE 1: BEST RESULTS PER METHOD\n",
    "# ============================================================\n",
    "\n",
    "def generate_best_results_table():\n",
    "    \"\"\"Generate LaTeX table of best results for each method.\"\"\"\n",
    "    \n",
    "    # Get best result per method\n",
    "    best_results = all_results.loc[all_results.groupby('method')['f1_score'].idxmax()][\n",
    "        ['method', 'model', 'n_features', 'f1_score', 'auc']\n",
    "    ].sort_values('f1_score', ascending=False)\n",
    "    \n",
    "    # Calculate feature reduction\n",
    "    baseline_features = baseline['n_features'].iloc[0]\n",
    "    best_results['reduction_pct'] = ((baseline_features - best_results['n_features']) / baseline_features * 100).round(1)\n",
    "    \n",
    "    # Start LaTeX table\n",
    "    latex = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Best Performance of Each Feature Selection Method}\n",
    "\\label{tab:best_results}\n",
    "\\begin{tabular}{lcccccc}\n",
    "\\hline\n",
    "\\textbf{Method} & \\textbf{Model} & \\textbf{Features} & \\textbf{Reduction} & \\textbf{F1 Score} & \\textbf{AUC} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    # Add rows\n",
    "    for idx, row in best_results.iterrows():\n",
    "        method_name = row['method'].replace('_', ' ').title()\n",
    "        model_name = row['model'].replace('_', ' ').title()\n",
    "        \n",
    "        latex += f\"{method_name} & {model_name} & {int(row['n_features'])} & {row['reduction_pct']:.1f}\\\\% & {row['f1_score']:.4f} & {row['auc']:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    # Add baseline for comparison\n",
    "    baseline_row = baseline.iloc[0]\n",
    "    latex += r\"\\hline\" + \"\\n\"\n",
    "    latex += f\"Baseline (No FS) & {baseline_row['model'].replace('_', ' ').title()} & {int(baseline_row['n_features'])} & 0.0\\\\% & {baseline_row['f1_score']:.4f} & {baseline_row['auc']:.4f} \\\\\\\\\\n\"\n",
    "    \n",
    "    # Close table\n",
    "    latex += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "table1 = generate_best_results_table()\n",
    "print(\"TABLE 1: Best Results Per Method\")\n",
    "print(\"=\"*60)\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2979f-09e2-43a4-9736-069c3da4c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. TABLE 2: PERFORMANCE BY NUMBER OF FEATURES\n",
    "# ============================================================\n",
    "\n",
    "def generate_performance_by_features_table(feature_counts=[10, 20, 30]):\n",
    "    \"\"\"Generate LaTeX table showing performance at different feature counts.\"\"\"\n",
    "    \n",
    "    latex = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Average F1 Score by Feature Selection Method and Number of Features}\n",
    "\\label{tab:performance_by_features}\n",
    "\\begin{tabular}{l\"\"\" + \"c\" * len(feature_counts) + r\"\"\"}\n",
    "\\hline\n",
    "\\textbf{Method} \"\"\"\n",
    "    \n",
    "    # Add column headers\n",
    "    for fc in feature_counts:\n",
    "        latex += f\"& \\\\textbf{{{fc} features}} \"\n",
    "    latex += r\"\\\\\" + \"\\n\\\\hline\\n\"\n",
    "    \n",
    "    # Get average F1 for each method and feature count\n",
    "    methods = sorted([m for m in all_results['method'].unique() if m != 'baseline'])\n",
    "    \n",
    "    for method in methods:\n",
    "        method_data = all_results[all_results['method'] == method]\n",
    "        method_name = method.replace('_', ' ').title()\n",
    "        \n",
    "        latex += f\"{method_name} \"\n",
    "        \n",
    "        for fc in feature_counts:\n",
    "            fc_data = method_data[method_data['n_features'] == fc]\n",
    "            if len(fc_data) > 0:\n",
    "                avg_f1 = fc_data['f1_score'].mean()\n",
    "                latex += f\"& {avg_f1:.4f} \"\n",
    "            else:\n",
    "                latex += \"& --- \"\n",
    "        \n",
    "        latex += r\"\\\\\" + \"\\n\"\n",
    "    \n",
    "    # Add baseline\n",
    "    latex += r\"\\hline\" + \"\\n\"\n",
    "    baseline_f1 = baseline['f1_score'].mean()\n",
    "    baseline_features = int(baseline['n_features'].iloc[0])\n",
    "    latex += f\"Baseline ({baseline_features} features) \"\n",
    "    for _ in feature_counts:\n",
    "        latex += f\"& {baseline_f1:.4f} \"\n",
    "    latex += r\"\\\\\" + \"\\n\"\n",
    "    \n",
    "    # Close table\n",
    "    latex += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "table2 = generate_performance_by_features_table()\n",
    "print(\"\\nTABLE 2: Performance by Number of Features\")\n",
    "print(\"=\"*60)\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e729b15-d07b-4cef-b13a-16f560a984a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. TABLE 3: METHOD COMPARISON BY CATEGORY\n",
    "# ============================================================\n",
    "\n",
    "def generate_category_comparison_table():\n",
    "    \"\"\"Generate LaTeX table comparing method categories.\"\"\"\n",
    "    \n",
    "    categories = {\n",
    "        'Traditional': ['correlation', 'variance', 'chi_square'],\n",
    "        'Embedded': ['l1_lasso', 'l2_ridge'],\n",
    "        'XAI-Based': ['shap', 'lime'],\n",
    "        'Optimization': ['pso', 'differential_evolution']\n",
    "    }\n",
    "    \n",
    "    latex = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Feature Selection Method Comparison by Category}\n",
    "\\label{tab:category_comparison}\n",
    "\\begin{tabular}{lccccc}\n",
    "\\hline\n",
    "\\textbf{Category} & \\textbf{Best Method} & \\textbf{Features} & \\textbf{F1 Score} & \\textbf{AUC} & \\textbf{Reduction} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    baseline_features = baseline['n_features'].iloc[0]\n",
    "    \n",
    "    for category, methods in categories.items():\n",
    "        cat_results = all_results[all_results['method'].isin(methods)]\n",
    "        if len(cat_results) > 0:\n",
    "            best = cat_results.loc[cat_results['f1_score'].idxmax()]\n",
    "            reduction = (1 - best['n_features'] / baseline_features) * 100\n",
    "            \n",
    "            best_method = best['method'].replace('_', ' ').title()\n",
    "            \n",
    "            latex += f\"{category} & {best_method} & {int(best['n_features'])} & {best['f1_score']:.4f} & {best['auc']:.4f} & {reduction:.1f}\\\\% \\\\\\\\\\n\"\n",
    "    \n",
    "    # Add baseline\n",
    "    latex += r\"\\hline\" + \"\\n\"\n",
    "    baseline_row = baseline.iloc[0]\n",
    "    latex += f\"Baseline & All Features & {int(baseline_row['n_features'])} & {baseline_row['f1_score']:.4f} & {baseline_row['auc']:.4f} & 0.0\\\\% \\\\\\\\\\n\"\n",
    "    \n",
    "    # Close table\n",
    "    latex += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "table3 = generate_category_comparison_table()\n",
    "print(\"\\nTABLE 3: Category Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(table3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f959a-ab9b-46b1-9215-021a95ed117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. TABLE 4: MODEL PERFORMANCE COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "def generate_model_comparison_table():\n",
    "    \"\"\"Generate LaTeX table comparing models across methods.\"\"\"\n",
    "    \n",
    "    models = sorted(all_results['model'].unique())\n",
    "    methods = sorted([m for m in all_results['method'].unique() if m != 'baseline'])[:6]  # Top 6 methods\n",
    "    \n",
    "    latex = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Maximum F1 Score by Model and Feature Selection Method}\n",
    "\\label{tab:model_comparison}\n",
    "\\begin{tabular}{l\"\"\" + \"c\" * len(models) + r\"\"\"}\n",
    "\\hline\n",
    "\\textbf{Method} \"\"\"\n",
    "    \n",
    "    # Add column headers\n",
    "    for model in models:\n",
    "        model_name = model.replace('_', ' ').title()\n",
    "        latex += f\"& \\\\textbf{{{model_name}}} \"\n",
    "    latex += r\"\\\\\" + \"\\n\\\\hline\\n\"\n",
    "    \n",
    "    # Add rows for each method\n",
    "    for method in methods:\n",
    "        method_data = all_results[all_results['method'] == method]\n",
    "        method_name = method.replace('_', ' ').title()\n",
    "        \n",
    "        latex += f\"{method_name} \"\n",
    "        \n",
    "        for model in models:\n",
    "            model_data = method_data[method_data['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                max_f1 = model_data['f1_score'].max()\n",
    "                latex += f\"& {max_f1:.4f} \"\n",
    "            else:\n",
    "                latex += \"& --- \"\n",
    "        \n",
    "        latex += r\"\\\\\" + \"\\n\"\n",
    "    \n",
    "    # Add baseline\n",
    "    latex += r\"\\hline\" + \"\\n\"\n",
    "    latex += \"Baseline \"\n",
    "    for model in models:\n",
    "        baseline_model = baseline[baseline['model'] == model]\n",
    "        if len(baseline_model) > 0:\n",
    "            latex += f\"& {baseline_model['f1_score'].iloc[0]:.4f} \"\n",
    "        else:\n",
    "            latex += \"& --- \"\n",
    "    latex += r\"\\\\\" + \"\\n\"\n",
    "    \n",
    "    # Close table\n",
    "    latex += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "table4 = generate_model_comparison_table()\n",
    "print(\"\\nTABLE 4: Model Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(table4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdb9b5-1b74-42de-8ecf-a3f65e374f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. TABLE 5: TOP SELECTED FEATURES\n",
    "# ============================================================\n",
    "\n",
    "def generate_top_features_table(top_n=15):\n",
    "    \"\"\"Generate LaTeX table of most frequently selected features.\"\"\"\n",
    "    \n",
    "    freq_df = pd.read_csv(\"results/comparisons/tables/feature_frequency.csv\")\n",
    "    top_features = freq_df.head(top_n)\n",
    "    \n",
    "    latex = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Top \"\"\" + str(top_n) + r\"\"\" Most Frequently Selected Features Across All Methods}\n",
    "\\label{tab:top_features}\n",
    "\\begin{tabular}{clc}\n",
    "\\hline\n",
    "\\textbf{Rank} & \\textbf{Feature Name} & \\textbf{Selection Frequency} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "    \n",
    "    for i, (idx, row) in enumerate(top_features.iterrows(), 1):\n",
    "        feature_name = row['feature'].replace('_', '\\\\_')  # Escape underscores for LaTeX\n",
    "        latex += f\"{i} & {feature_name} & {int(row['frequency'])} \\\\\\\\\\n\"\n",
    "    \n",
    "    # Close table\n",
    "    latex += r\"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    return latex\n",
    "\n",
    "table5 = generate_top_features_table()\n",
    "print(\"\\nTABLE 5: Top Selected Features\")\n",
    "print(\"=\"*60)\n",
    "print(table5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dfbbb-9302-430a-9cfc-28a14cd20a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. SAVE ALL TABLES\n",
    "# ============================================================\n",
    "\n",
    "output_dir = Path(\"results/comparisons/reports\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save individual tables\n",
    "tables = {\n",
    "    \"table1_best_results.tex\": table1,\n",
    "    \"table2_performance_by_features.tex\": table2,\n",
    "    \"table3_category_comparison.tex\": table3,\n",
    "    \"table4_model_comparison.tex\": table4,\n",
    "    \"table5_top_features.tex\": table5\n",
    "}\n",
    "\n",
    "for filename, content in tables.items():\n",
    "    filepath = output_dir / filename\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"âœ“ Saved: {filename}\")\n",
    "\n",
    "# Create combined file with all tables\n",
    "combined = r\"\"\"\\documentclass{article}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{multirow}\n",
    "\\begin{document}\n",
    "\n",
    "% ==================================================\n",
    "% TABLE 1: Best Results Per Method\n",
    "% ==================================================\n",
    "\n",
    "\"\"\" + table1 + r\"\"\"\n",
    "\n",
    "\\newpage\n",
    "\n",
    "% ==================================================\n",
    "% TABLE 2: Performance by Number of Features\n",
    "% ==================================================\n",
    "\n",
    "\"\"\" + table2 + r\"\"\"\n",
    "\n",
    "\\newpage\n",
    "\n",
    "% ==================================================\n",
    "% TABLE 3: Category Comparison\n",
    "% ==================================================\n",
    "\n",
    "\"\"\" + table3 + r\"\"\"\n",
    "\n",
    "\\newpage\n",
    "\n",
    "% ==================================================\n",
    "% TABLE 4: Model Comparison\n",
    "% ==================================================\n",
    "\n",
    "\"\"\" + table4 + r\"\"\"\n",
    "\n",
    "\\newpage\n",
    "\n",
    "% ==================================================\n",
    "% TABLE 5: Top Selected Features\n",
    "% ==================================================\n",
    "\n",
    "\"\"\" + table5 + r\"\"\"\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / \"all_tables_combined.tex\", 'w') as f:\n",
    "    f.write(combined)\n",
    "\n",
    "print(f\"\\nâœ“ Saved: all_tables_combined.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199390c-cc45-4a8a-837e-f4a4b02319d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. GENERATE USAGE INSTRUCTIONS\n",
    "# ============================================================\n",
    "\n",
    "instructions = \"\"\"\n",
    "# HOW TO USE LATEX TABLES IN YOUR THESIS\n",
    "\n",
    "## Individual Tables\n",
    "Each table is saved as a separate .tex file in:\n",
    "`results/comparisons/reports/`\n",
    "\n",
    "### Copy-Paste Method:\n",
    "1. Open the .tex file you need (e.g., table1_best_results.tex)\n",
    "2. Copy the entire content\n",
    "3. Paste into your thesis .tex file where you want the table\n",
    "\n",
    "### Include Method:\n",
    "In your thesis .tex file:\n",
    "```latex\n",
    "\\\\input{results/comparisons/reports/table1_best_results.tex}\n",
    "```\n",
    "\n",
    "## All Tables Combined\n",
    "File: `all_tables_combined.tex`\n",
    "This is a complete LaTeX document with all tables.\n",
    "\n",
    "To compile:\n",
    "```bash\n",
    "pdflatex all_tables_combined.tex\n",
    "```\n",
    "\n",
    "## Customization Tips\n",
    "\n",
    "### Adjust Column Widths:\n",
    "Replace `\\begin{tabular}{lcccc}` with specific widths:\n",
    "```latex\n",
    "\\\\begin{tabular}{p{3cm}p{2cm}p{2cm}p{2cm}p{2cm}}\n",
    "```\n",
    "\n",
    "### Add Colors (requires xcolor package):\n",
    "```latex\n",
    "\\\\usepackage[table]{xcolor}\n",
    "\\\\rowcolor{gray!20} % Add before row\n",
    "```\n",
    "\n",
    "### Use booktabs for professional look:\n",
    "Already included! Uses \\\\hline for lines.\n",
    "\n",
    "### Adjust Caption Position:\n",
    "Move `\\\\caption{}` after `\\\\begin{tabular}` to place it at bottom\n",
    "\n",
    "## Required Packages\n",
    "Add to your thesis preamble:\n",
    "```latex\n",
    "\\\\usepackage{booktabs}\n",
    "\\\\usepackage{multirow}\n",
    "\\\\usepackage{graphicx}\n",
    "```\n",
    "\n",
    "## Tables Generated:\n",
    "1. table1_best_results.tex - Best performance per method\n",
    "2. table2_performance_by_features.tex - F1 scores at different feature counts\n",
    "3. table3_category_comparison.tex - Comparison by method category\n",
    "4. table4_model_comparison.tex - Model performance comparison\n",
    "5. table5_top_features.tex - Most frequently selected features\n",
    "\n",
    "Choose the tables most relevant to your thesis discussion!\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / \"USAGE_INSTRUCTIONS.md\", 'w') as f:\n",
    "    f.write(instructions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LATEX TABLE GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(f\"  ðŸ“„ Individual tables (5): {output_dir}/\")\n",
    "print(f\"  ðŸ“„ Combined document: all_tables_combined.tex\")\n",
    "print(f\"  ðŸ“„ Instructions: USAGE_INSTRUCTIONS.md\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Review the .tex files\")\n",
    "print(\"  2. Copy tables into your thesis\")\n",
    "print(\"  3. Compile and verify formatting\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
