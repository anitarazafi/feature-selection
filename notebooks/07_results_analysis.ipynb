{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddabb782-3d1b-4224-9913-28b07becffa2",
   "metadata": {},
   "source": [
    "### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd8b24-c4ad-4292-bae1-19abce616392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE SELECTION RESULTS ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directories\n",
    "Path(\"results/comparisons/plots\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"results/comparisons/reports\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5462f-98a0-4821-b0f0-86566c8aa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. LOAD ALL RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading results...\")\n",
    "\n",
    "# Load each experiment's results\n",
    "baseline = pd.read_csv(\"results/comparisons/tables/baseline_ibtracs.last3years.csv\")\n",
    "traditional = pd.read_csv(\"results/comparisons/tables/traditional_fs_ibtracs.last3years.csv\")\n",
    "embedded = pd.read_csv(\"results/comparisons/tables/embedded_fs_ibtracs.last3years.csv\")\n",
    "xai = pd.read_csv(\"results/comparisons/tables/xai_fs_ibtracs.last3years.csv\")\n",
    "optimization = pd.read_csv(\"results/comparisons/tables/optimization_fs_ibtracs.last3years.csv\")\n",
    "\n",
    "# Combine all results\n",
    "all_results = pd.concat([baseline, traditional, embedded, xai, optimization], ignore_index=True)\n",
    "\n",
    "# Save combined results\n",
    "all_results.to_csv(\"results/comparisons/tables/all_methods_combined.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ Loaded {len(all_results)} experiments\")\n",
    "print(f\"âœ“ Methods: {all_results['method'].nunique()}\")\n",
    "print(f\"âœ“ Models: {all_results['model'].nunique()}\")\n",
    "print(f\"\\nDataset preview:\")\n",
    "print(all_results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d68aa-9e9f-463f-9396-86064eaa0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. SUMMARY STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall statistics by method\n",
    "method_summary = all_results.groupby('method').agg({\n",
    "    'n_features': ['min', 'max', 'mean'],\n",
    "    'f1_score': ['min', 'max', 'mean'],\n",
    "    'auc': ['mean'],\n",
    "    'train_time': ['mean']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nPerformance by Method:\")\n",
    "print(method_summary)\n",
    "\n",
    "# Best result for each method\n",
    "best_per_method = all_results.loc[all_results.groupby('method')['f1_score'].idxmax()][\n",
    "    ['method', 'model', 'n_features', 'f1_score', 'auc']\n",
    "].sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST RESULT PER METHOD\")\n",
    "print(\"=\"*60)\n",
    "print(best_per_method.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "best_per_method.to_csv(\"results/comparisons/tables/best_results_per_method.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41124ed-1df8-482a-b33d-9823c12e73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. PLOT 1: F1 SCORE VS NUMBER OF FEATURES\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get baseline F1 for reference\n",
    "baseline_f1 = baseline['f1_score'].mean()\n",
    "baseline_features = baseline['n_features'].iloc[0]\n",
    "\n",
    "# Plot each method\n",
    "methods = all_results['method'].unique()\n",
    "colors = sns.color_palette(\"husl\", len(methods))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    method_data = all_results[all_results['method'] == method]\n",
    "    \n",
    "    # Average F1 by number of features\n",
    "    avg_by_features = method_data.groupby('n_features').agg({\n",
    "        'f1_score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    plt.plot(\n",
    "        avg_by_features['n_features'], \n",
    "        avg_by_features['f1_score'],\n",
    "        marker='o', \n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        label=method.replace('_', ' ').title(),\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "# Add baseline reference line\n",
    "plt.axhline(\n",
    "    y=baseline_f1, \n",
    "    color='red', \n",
    "    linestyle='--', \n",
    "    linewidth=2,\n",
    "    label=f'Baseline (F1={baseline_f1:.3f}, {baseline_features} features)'\n",
    ")\n",
    "\n",
    "plt.xlabel('Number of Features', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "plt.title('Feature Selection Methods: F1 Score vs Number of Features', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc='best', fontsize=11, framealpha=0.9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('results/comparisons/plots/f1_vs_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: f1_vs_features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56830826-4745-4b59-806b-06976655a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. PLOT 2: PERFORMANCE HEATMAP (METHOD Ã— MODEL)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create pivot table: max F1 score for each method-model combination\n",
    "pivot = all_results.pivot_table(\n",
    "    values='f1_score',\n",
    "    index='method',\n",
    "    columns='model',\n",
    "    aggfunc='max'\n",
    ")\n",
    "\n",
    "# Clean up names\n",
    "pivot.index = [x.replace('_', ' ').title() for x in pivot.index]\n",
    "pivot.columns = [x.replace('_', ' ').title() for x in pivot.columns]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    pivot, \n",
    "    annot=True, \n",
    "    fmt='.4f', \n",
    "    cmap='RdYlGn',\n",
    "    vmin=0.70,\n",
    "    vmax=0.90,\n",
    "    cbar_kws={'label': 'F1 Score'},\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.title('Best F1 Score by Feature Selection Method and Model', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Feature Selection Method', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('results/comparisons/plots/method_model_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: method_model_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277f062-12e3-4cc0-858b-27521e99560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. PLOT 3: FEATURE REDUCTION EFFICIENCY\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Get best result per method\n",
    "best_results = all_results.loc[all_results.groupby('method')['f1_score'].idxmax()]\n",
    "\n",
    "# Calculate feature reduction percentage\n",
    "best_results['reduction_pct'] = (1 - best_results['n_features'] / baseline_features) * 100\n",
    "\n",
    "# Sort by F1 score\n",
    "best_results = best_results.sort_values('f1_score', ascending=True)\n",
    "\n",
    "# Create horizontal bar chart\n",
    "bars = ax.barh(\n",
    "    range(len(best_results)),\n",
    "    best_results['f1_score'],\n",
    "    color=sns.color_palette(\"viridis\", len(best_results))\n",
    ")\n",
    "\n",
    "# Add feature count labels\n",
    "for i, (idx, row) in enumerate(best_results.iterrows()):\n",
    "    ax.text(\n",
    "        row['f1_score'] + 0.005,\n",
    "        i,\n",
    "        f\"{int(row['n_features'])} features\\n({row['reduction_pct']:.0f}% reduction)\",\n",
    "        va='center',\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "# Formatting\n",
    "ax.set_yticks(range(len(best_results)))\n",
    "ax.set_yticklabels([x.replace('_', ' ').title() for x in best_results['method']])\n",
    "ax.set_xlabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Feature Selection Efficiency: F1 Score vs Feature Reduction', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.axvline(x=baseline_f1, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/comparisons/plots/feature_reduction_efficiency.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: feature_reduction_efficiency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c767a-5181-44aa-a23a-982903ef3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. PLOT 4: AUC COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Box plot of AUC scores by method\n",
    "methods_for_plot = all_results['method'].unique()\n",
    "data_for_box = [all_results[all_results['method'] == m]['auc'].values for m in methods_for_plot]\n",
    "\n",
    "bp = plt.boxplot(\n",
    "    data_for_box,\n",
    "    labels=[x.replace('_', ' ').title() for x in methods_for_plot],\n",
    "    patch_artist=True,\n",
    "    showmeans=True\n",
    ")\n",
    "\n",
    "# Color the boxes\n",
    "colors = sns.color_palette(\"Set2\", len(methods_for_plot))\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add baseline reference\n",
    "baseline_auc = baseline['auc'].mean()\n",
    "plt.axhline(y=baseline_auc, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Baseline AUC={baseline_auc:.4f}')\n",
    "\n",
    "plt.xlabel('Feature Selection Method', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('AUC Score', fontsize=14, fontweight='bold')\n",
    "plt.title('AUC Score Distribution by Feature Selection Method', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('results/comparisons/plots/auc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: auc_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cbfe9-49c5-4ac9-a678-354a23994201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. PLOT 5: TRAINING TIME COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Average training time by method and feature count\n",
    "time_data = all_results.groupby(['method', 'n_features']).agg({\n",
    "    'train_time': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "methods = time_data['method'].unique()\n",
    "colors = sns.color_palette(\"husl\", len(methods))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    method_time = time_data[time_data['method'] == method]\n",
    "    plt.plot(\n",
    "        method_time['n_features'],\n",
    "        method_time['train_time'],\n",
    "        marker='o',\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        label=method.replace('_', ' ').title(),\n",
    "        color=colors[i]\n",
    "    )\n",
    "\n",
    "plt.xlabel('Number of Features', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Average Training Time (seconds)', fontsize=14, fontweight='bold')\n",
    "plt.title('Training Time vs Number of Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('results/comparisons/plots/training_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: training_time_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d1349-cc63-450d-85d8-b6e73f8311b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. ANALYSIS: MINIMUM FEATURES FOR BASELINE PERFORMANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MINIMUM FEATURES TO MATCH BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_threshold = baseline_f1 * 0.98  # Within 2% of baseline\n",
    "\n",
    "# Find minimum features that achieve threshold per method\n",
    "competitive = all_results[all_results['f1_score'] >= baseline_threshold]\n",
    "\n",
    "min_features_per_method = competitive.groupby('method').agg({\n",
    "    'n_features': 'min',\n",
    "    'f1_score': 'max'\n",
    "}).round(4)\n",
    "\n",
    "min_features_per_method = min_features_per_method.sort_values('n_features')\n",
    "\n",
    "print(f\"\\nBaseline F1: {baseline_f1:.4f}\")\n",
    "print(f\"Threshold (98% of baseline): {baseline_threshold:.4f}\\n\")\n",
    "print(min_features_per_method)\n",
    "\n",
    "# Save\n",
    "min_features_per_method.to_csv(\"results/comparisons/tables/min_features_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93f1a1-7799-47a5-8e7c-7b864b0dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. FEATURE FREQUENCY ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MOST FREQUENTLY SELECTED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load selected features from all methods\n",
    "feature_frequency = {}\n",
    "\n",
    "methods_dirs = {\n",
    "    'correlation': 'results/features/ibtracs.last3years/correlation',\n",
    "    'variance': 'results/features/ibtracs.last3years/variance',\n",
    "    'chi_square': 'results/features/ibtracs.last3years/chi_square',\n",
    "    'l1_lasso': 'results/features/ibtracs.last3years/l1_lasso',\n",
    "    'l2_ridge': 'results/features/ibtracs.last3years/l2_ridge',\n",
    "    'shap': 'results/features/ibtracs.last3years/shap',\n",
    "    'lime': 'results/features/ibtracs.last3years/lime',\n",
    "    'pso': 'results/features/ibtracs.last3years/pso',\n",
    "    'differential_evolution': 'results/features/ibtracs.last3years/differential_evolution'\n",
    "}\n",
    "\n",
    "for method_name, method_dir in methods_dirs.items():\n",
    "    method_path = Path(method_dir)\n",
    "    if method_path.exists():\n",
    "        # Get all JSON files\n",
    "        for json_file in method_path.glob(\"*.json\"):\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                selected = data.get('selected_features', [])\n",
    "                \n",
    "                for feature in selected:\n",
    "                    feature_frequency[feature] = feature_frequency.get(feature, 0) + 1\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_features = sorted(feature_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 20 most frequently selected features:\")\n",
    "for i, (feature, count) in enumerate(sorted_features[:20], 1):\n",
    "    print(f\"{i:2d}. {feature:40s} - selected {count} times\")\n",
    "\n",
    "# Save to CSV\n",
    "freq_df = pd.DataFrame(sorted_features, columns=['feature', 'frequency'])\n",
    "freq_df.to_csv(\"results/comparisons/tables/feature_frequency.csv\", index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Saved feature frequency analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd17b96-5d31-4448-a336-9348b806e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. PLOT 6: TOP FEATURES FREQUENCY\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "top_features = freq_df.head(15)\n",
    "\n",
    "bars = plt.barh(\n",
    "    range(len(top_features)),\n",
    "    top_features['frequency'],\n",
    "    color=sns.color_palette(\"viridis\", len(top_features))\n",
    ")\n",
    "\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Selection Frequency', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=14, fontweight='bold')\n",
    "plt.title('Top 15 Most Frequently Selected Features Across All Methods', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(top_features.iterrows()):\n",
    "    plt.text(row['frequency'] + 0.3, i, str(int(row['frequency'])), \n",
    "             va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/comparisons/plots/top_features_frequency.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: top_features_frequency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8ab61-62dc-4bf8-b316-abc135ded7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 11. FINAL SUMMARY REPORT\n",
    "# ============================================================\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "# FEATURE SELECTION RESULTS SUMMARY\n",
    "{'='*60}\n",
    "\n",
    "## Dataset Information\n",
    "- Dataset: IBTrACS (Last 3 Years)\n",
    "- Original Features: {baseline_features}\n",
    "- Training Samples: {all_results['dataset'].value_counts().iloc[0] if len(all_results) > 0 else 'N/A'}\n",
    "- Class Imbalance: ~89% majority class\n",
    "\n",
    "## Baseline Performance (All {baseline_features} Features)\n",
    "- Average F1 Score: {baseline_f1:.4f}\n",
    "- Average AUC: {baseline['auc'].mean():.4f}\n",
    "\n",
    "## Best Results by Method Category\n",
    "\n",
    "### Traditional Methods:\n",
    "\"\"\"\n",
    "\n",
    "# Add best from each category\n",
    "categories = {\n",
    "    'Traditional': ['correlation', 'variance', 'chi_square'],\n",
    "    'Embedded': ['l1_lasso', 'l2_ridge'],\n",
    "    'XAI-Based': ['shap', 'lime'],\n",
    "    'Optimization': ['pso', 'differential_evolution']\n",
    "}\n",
    "\n",
    "for category, methods in categories.items():\n",
    "    cat_results = all_results[all_results['method'].isin(methods)]\n",
    "    if len(cat_results) > 0:\n",
    "        best = cat_results.loc[cat_results['f1_score'].idxmax()]\n",
    "        summary_text += f\"\\n### {category}:\\n\"\n",
    "        summary_text += f\"- Best Method: {best['method'].replace('_', ' ').title()}\\n\"\n",
    "        summary_text += f\"- Features: {int(best['n_features'])} ({(1 - best['n_features']/baseline_features)*100:.1f}% reduction)\\n\"\n",
    "        summary_text += f\"- F1 Score: {best['f1_score']:.4f}\\n\"\n",
    "        summary_text += f\"- AUC: {best['auc']:.4f}\\n\"\n",
    "        summary_text += f\"- Model: {best['model'].replace('_', ' ').title()}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "\n",
    "## Key Findings:\n",
    "\n",
    "1. **Most Efficient Method**: {best_per_method.iloc[0]['method'].replace('_', ' ').title()}\n",
    "   - Achieved F1={best_per_method.iloc[0]['f1_score']:.4f} with only {int(best_per_method.iloc[0]['n_features'])} features\n",
    "   - Feature reduction: {(1 - best_per_method.iloc[0]['n_features']/baseline_features)*100:.1f}%\n",
    "\n",
    "2. **Minimum Features for Baseline Performance**:\n",
    "   - Need approximately {min_features_per_method['n_features'].min():.0f}-{min_features_per_method['n_features'].quantile(0.5):.0f} features\n",
    "   - To maintain F1 â‰¥ {baseline_threshold:.4f}\n",
    "\n",
    "3. **Most Frequently Selected Features**:\n",
    "   - Top feature: {sorted_features[0][0]} (selected {sorted_features[0][1]} times)\n",
    "   - Indicates consistent importance across methods\n",
    "\n",
    "4. **Training Efficiency**:\n",
    "   - Feature selection reduces training time\n",
    "   - Average time with 20 features: ~{all_results[all_results['n_features'] == 20]['train_time'].mean():.3f}s\n",
    "   - Vs. baseline: ~{baseline['train_time'].mean():.3f}s\n",
    "\n",
    "## Recommendations:\n",
    "\n",
    "1. **For Maximum Compression**: Use {best_per_method.iloc[0]['method'].replace('_', ' ').title()}\n",
    "   - Minimal features while maintaining performance\n",
    "\n",
    "2. **For Interpretability**: Use SHAP or LIME\n",
    "   - Provides explanations for feature importance\n",
    "\n",
    "3. **For Robustness**: Use optimization methods (PSO/DE)\n",
    "   - Explores feature interactions comprehensively\n",
    "\n",
    "## Files Generated:\n",
    "- Plots: results/comparisons/plots/\n",
    "- Tables: results/comparisons/tables/\n",
    "- Feature lists: results/features/\n",
    "\n",
    "{'='*60}\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "with open(\"results/comparisons/reports/thesis_summary.md\", \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(summary_text)\n",
    "print(\"\\nâœ“ Saved: thesis_summary.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fefb0-db07-48fa-819d-e1749716a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 12. COMPLETION MESSAGE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  ðŸ“Š Plots (6): results/comparisons/plots/\")\n",
    "print(\"  ðŸ“‹ Tables (4): results/comparisons/tables/\")\n",
    "print(\"  ðŸ“„ Summary: results/comparisons/reports/thesis_summary.md\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Review the plots and tables\")\n",
    "print(\"  2. Identify key findings for your thesis\")\n",
    "print(\"  3. Generate LaTeX tables (run next notebook)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
